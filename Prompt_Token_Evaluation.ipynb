{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "OpenAI Uses Prompts and meausres them as Token for Model input and output"
      ],
      "metadata": {
        "id": "GK-_aolWru3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade tiktoken\n",
        "%pip install --upgrade openai"
      ],
      "metadata": {
        "id": "R33Q1dYHrvSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#token counter test code.\n",
        "import tiktoken\n",
        "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
        "assert enc.decode(enc.encode(\"hello world\")) == \"hello world\"\n",
        "print(enc.encode(\"Hello, I am in the world of AI.\"))\n",
        "num_tokens = len(enc.encode(\"Hello, I am in the world of AI.\"))\n",
        "print(num_tokens)\n",
        "enc.decode([9906, 11, 358, 1097, 304, 279, 1917, 315, 15592, 13])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "CqhV4frJrct8",
        "outputId": "11d826db-be34-4d6e-9b82-9c966bac2eca"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9906, 11, 358, 1097, 304, 279, 1917, 315, 15592, 13]\n",
            "10\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello, I am in the world of AI.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###Token counter.\n",
        "import tiktoken\n",
        "\n",
        "def token_counter(input_text):\n",
        "  enc = tiktoken.get_encoding(\"cl100k_base\")\n",
        "  num_tokens = len(enc.encode(input_text))\n",
        "  #print(num_tokens)\n",
        "  # To get the tokeniser corresponding to a specific model in the OpenAI API:\n",
        "  return num_tokens"
      ],
      "metadata": {
        "id": "2BdRUEVHrh62"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Token count should be within the limit, else model API will throw a HTTP 404 error code.\n",
        "Note: The Token count is per request and applies to everything in the request and response"
      ],
      "metadata": {
        "id": "XtMwypwMsIpi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token_counter(\"Hello, I am in the world of AI.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QteRRtlMrk6-",
        "outputId": "80397d24-e826-43b0-b5d2-3c0e0fae8f3d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}